{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T22:40:03.586969800Z",
     "start_time": "2024-04-23T22:40:02.019465900Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T22:40:03.570939400Z"
    }
   },
   "outputs": [],
   "source": [
    "_=load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1882\n",
      "1219\n",
      "52\n",
      "714\n",
      "46\n",
      "2375\n",
      "43\n",
      "1947\n",
      "4373\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Funci칩n para leer los archivos a pasar a OpenAI\n",
    "def process_files_in_folder(folder_path): # -> List[List[str]]:\n",
    "    # Verificamos si la ruta proporcionada es una carpeta\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(\"La ruta proporcionada no es una carpeta v치lida.\")\n",
    "        return None\n",
    "\n",
    "    data = []\n",
    "    # Recorremos los archivos en la carpeta\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Verificamos si el elemento en la carpeta es un archivo\n",
    "        if os.path.isfile(file_path):\n",
    "            # Llamamos a la funci칩n textloader con la ruta del archivo\n",
    "            loader = TextLoader(file_path)\n",
    "            doc = loader.load()\n",
    "            splits = text_splitter.split_documents(doc)\n",
    "            data.append(splits)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Ruta de la carpeta que contiene los archivos\n",
    "folder_path = \"files\"\n",
    "\n",
    "# Llamamos a la funci칩n para procesar los archivos en la carpeta\n",
    "processed_data = process_files_in_folder(folder_path)\n",
    "\n",
    "total_splits = []\n",
    "# Ahora puedes hacer algo con los datos procesados, como imprimirlos\n",
    "for document in processed_data:\n",
    "    print(len(document))\n",
    "    total_splits.extend(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_splits = []\n",
    "for document in processed_data: # Crear un solo documento con todos los splits\n",
    "    total_splits.extend(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12802"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "#Es una base de datos de embdings, te convierte tu texto en enveding y te lo guarda en una base de datos\n",
    "#vectorstore = Chroma(\n",
    "#    all_splits,\n",
    "#    embedding_function = OpenAIEmbeddings(),\n",
    "#    persist_directory = \"test/chroma_db\"\n",
    "#)\n",
    "\n",
    "vectorstore = Chroma.from_documents(total_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "retriever = vectorstore.as_retriever()\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=llm,\n",
    "    memory_key= \"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever = retriever,\n",
    "    memory = memory\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://95fddad9f194f779ff.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://95fddad9f194f779ff.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chatbot(input_text):\n",
    "    response = qa(input_text)\n",
    "    return response[\"answer\"]\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "        gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Empieza a chattear con el gymbot!\n",
    "    \"\"\")\n",
    "\n",
    "chatbot_interface = gr.Interface(fn=chatbot, \n",
    "                                 inputs=\"textbox\", \n",
    "                                 outputs=\"textbox\",\n",
    "                                 description=\"Chatbot para responder preguntas sobre fitness\",\n",
    "                                 theme=\"soft\",\n",
    "                                 title=\"Gym Chatbot\")\n",
    "\n",
    "chatbot_interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
